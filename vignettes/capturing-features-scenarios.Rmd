---
title: "Capturing features and scenarios"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Capturing features and scenarios}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup-pickler, eval=FALSE, echo=FALSE}
install.packages("pak", repos = "http://cran.us.r-project.org")
pak::pkg_install("mjfrigaard/pickler", 
  upgrade = TRUE, ask = FALSE)
```

```{r setup-testthat, eval=FALSE, echo=FALSE}
pak::pkg_install("r-lib/testthat", 
  upgrade = TRUE, ask = FALSE)
```

```{r pkgs}
library(pickler)
library(testthat)
```

# Overview

This vignette covers how `pickler` extracts the test descriptions from `testthat`'s BDD functions. 

## Inspiration

`pickler::features()` creates a `FEATURES.md` file in the `tests/` folder. `FEATURES.md` compiles `description` arguments from any `describe()` calls, and the `desc` from `test_that()` (or the `description` argument in `it()`).

``` bash
tests/FEATURES.md
```

`tests/FEATURES.md` was inspired by the `tests/README.md` file generated by [`covrpage`](https://yonicd.github.io/covrpage/articles/tests_and_coverage.html). `tests/README.md` is created with `covrpage::covrpage()` and provides tabular summaries of test coverage, pass/fail status, time to execute, expectations, and the unit test descriptions/context in `tests/testthat/`. 

# The problem

Unfortunately, `covrpage::covrpage()` doesn't work well with multiline test descriptions passed to `describe()`, `it()`, or `test_that()`. This poses a problem for BDD or Gherkin-style test features and scenarios, as the keywords each begin on a new line.[^newline-gherkin] Below is an example using the `pickler::logo()` function:


```
Feature: Text-based Logo Generation
  As a user who calls the text_logo() function
  I want to generate a text-based 'pickler' logo  
  In order to have a visual representation in text form
  
  Scenario: User invokes the pickler::logo() function
    Given the user has access to the pickler::logo() function
    When the user calls the logo() function
    Then the ASCII 'pickler' logo is displayed in the console
```

[^newline-gherkin]: '[*Each line that isn’t a blank line has to start with a Gherkin keyword, followed by any text you like*](https://cucumber.io/docs/gherkin/reference/#keywords)'

## Parsing test files

To understand how `pickler` combines multiline descriptions from the `describe()`, `it()`, and `test_that()` calls into the `tests/FEATURES.md` file, we need to dive into how `covrpage` creates the `tests/README.md` file. 

When user's call `covrpage::covrpage()`, the test files are scanned for `describe()`, `it()`, and `test_that()` using the [`map_testthat()` function](https://github.com/yonicd/covrpage/blob/master/R/map_testthat.R). The two functions at the root of `map_testthat()`'s ability to generate the `tests/README.md` file are `parse()` & `getParseData()`:

  -   `parse()` returns the contents of a tests file (like `test-logo.R`), but wrapped in call to `expression()` (creating the 'list of calls')
  
      -   `keep.source = TRUE` keeps the *reference information.*
  
  -   When the output of `parse()` is passed to to `utils::getParseData()` (with `includeText` set to `TRUE`), the result is a `data.frame`. [^includetext-help]
  
Below is the parsed data from a `testthat` file for the `logo()` function (test also shown below):

*Contents of `test-logo.R`*:

```{r eval=FALSE}
test_that("Scenario: User stores the output of logo()",
  code = {
        # Then the contents of x should be NULL
        x <- logo()
        expect_null(x)
        # And the output if logo() is NULL
        expect_true(is.null(logo()))
})
```


```{r parsed_file}
parsed_file <- parse(file = system.file("dev", "tests", "testthat",
                                      "test-logo.R",
                                      package = "pickler"), 
                     keep.source = TRUE)
parsed_file_data <- utils::getParseData(x = parsed_file, includeText = TRUE)
str(parsed_file_data)
```

This `data.frame` is the object that stores the necessary data for each `describe()`, `it()`, `test_that()`, and `expect_*()` calls in our `tests/` folder.

### Token, terminal and text

The `token` contains the '*type of token*', and these don't have much in terms of documentation. tokens seem to resemble environmental variables (all caps), and the values we care about are `SYMBOL_FUNCTION_CALL` and `STR_CONST`. 

```{r}
subset(x = parsed_file_data, 
  token %in% c('SYMBOL_FUNCTION_CALL', 'STR_CONST'), 
  select = c(token, terminal)
  )
```

-   `terminal` is a `TRUE`/`FALSE` value listing if '*the `token` is a leaf in the parse tree*'
    -   `text` includes 'the text of all tokens'

    ```{r}
    subset(x = parsed_file_data, 
      token %in% c("SYMBOL_FUNCTION_CALL", "STR_CONST"),
      select = c(token, terminal, text)
      )
    ```

    
[^includetext-help]: The documentation for the `includeText` argument contains additional information that's relevant to our goals in `pickler`: '*If `includeText` is `TRUE`, the text of all tokens*'...'*Very long strings (with source of 1000 characters or more) will not be stored; a message giving their length and delimiter will be included instead.*'


### Line location columns 

+   `line1` & `line2` contain the beginning and ending line for each `token`

    -   For example, `expr` is the entire `test_that()` expresion, and it begins on line 1 and ends on line 8:
  
    ```{r}
    parsed_file_data[c('token', 'line1', 'line2')] |> 
      head()
    ```
    -   We can verify this with `readLines()`:
    ```{r}
    readLines(con = system.file("dev", "tests", "testthat",
                                      "test-logo.R",
                                      package = "pickler"))[1:8]
    ```
    -   `col1` & `col2` represent the column numbers where the `token` starts and ends, respectively
    
        -   For example, `test_that()` is a `SYMBOL_FUNCTION_CALL` with 9 characters:
    ```{r}
    nchar('test_that')
    ```
      -   *The first character is column 1*, so `test_that()` (a `SYMBOL_FUNCTION_CALL`) starts on column 1 and ends on column 9.
    ```{r}
    parsed_file_data[2, c('token', 'col1', 'col2')]
    ```
    -   `id`: the identifier for each item.
    -   `parent`: the identifier for the 'parent' of the item.

# `tests/README.md` internals

Now that we've covered what parsed data is available from the tests in the `tests/testthat/` folder, we can demonstrate how `covrpage` creates the `tests/README.md` file. In most R packages, there are multiple test files in the `tests/testthat/` folder. The `parsed_file_list` mimics two test files read from `tests/testthat/` (each of these tests have a single line description).[^dev-tests-testthat]

[^dev-tests-testthat]: These tests are stored in [`dev/tests/testthat/`](). 

```{r parsed_logo-parsed_pivot_string_long}
parsed_logo <- utils::getParseData(parse(system.file("dev", "tests", "testthat",
                                                     "test-logo.R",
                                                     package = "pickler"), 
                                          keep.source = TRUE), includeText = TRUE)
parsed_pivot_string_long <- utils::getParseData(parse(system.file("dev", 
                                                     "tests", "testthat",
                                                     "test-pivot_string_long.R",
                                                      package = "pickler"), 
                                          keep.source = TRUE), includeText = TRUE)
parsed_file_list <- list(
  'parsed_logo' = parsed_logo,
  'parsed_pivot_string_long' = parsed_pivot_string_long
  )
```

```{r, eval=FALSE, echo=TRUE}
fs::dir_tree(path = system.file("dev", "tests", package = "pickler"))
```

```bash
└── testthat
    ├── _snaps
    ├── test-logo.R
    ├── test-pivot_string_long.R
    ├── test-rev_string.R
    └── test-split_cols.R
```

## Expectations

The [`map_testthat()`](https://github.com/yonicd/covrpage/blob/master/R/map_testthat.R) and it's supporting functions are displayed below using the abstract syntax tree (`ast()`) function from the `lobstr` package:

```{r lobstr}
library(lobstr)
```

```{r ast-nest_expect, echo=FALSE, eval=TRUE, comment=''}
ast(
  nest_expect(
    get_expect(),
    unrowname()
  )
)
```

```{r ast-nest_expect-descr, echo=FALSE, eval=FALSE, comment=''}
ast(
  nest_expect("[x] = list of parsed data.frames from getParseData(parse())",
    get_expect("[x] = parsed data.frame from getParseData(parse())", 
               "[token_text] = '^expect_'"),
    unrowname("[el] = string element that will be used as the label for the new column" , 
              "[ret] = list of data.frames from which [el] is subsetted using ret[[el]]", 
              "[label] = column name added to the data.frame (contains value specified by [el])")
  )
)
```

The expectation functions (`expect_*()`) in the test files are parsed with `get_expect()`, `unrowname()` and `nest_expect()`. `pickler` uses a similar call stack, but with slightly different names (and arguments):

```{r ast-extract_expect, echo=FALSE, eval=TRUE, comment=''}
ast(
  extract_expects(
      match_expect(),
      add_lbl_col()
  )
)
```

```{r ast-extract_expect-descr, echo=FALSE, eval=FALSE, comment=''}
ast(
  extract_expects("[test_code_list]", 
    "applies match_expect() and add_lbl_col() to a list of parsed data.frames",
      match_expect(
        "[code_data]", 
        "[expectation_pattern] = '^expect_'",
        "returns data.frame of parsed file data with expectations and line numbers"),
      add_lbl_col(
        "[element_name] = ", 
        "[parsed_data_list] = ", 
        "[col_name] = ")
  )
)
```

### covrpage:::get_expect()

The expectations are extracted with `covrpage:::get_expect()`, which returns a `data.frame` with three columns: `expectation`, `line1` and `line2`.

```{r}
str(
  covrpage:::get_expect(
    x = parsed_file_data, 
    token_text = "^expect_")
)

```

#### pickler::match_expect()

I've rewritten the `get_expect()` as `match_expect()`, with new argument names and definitions: 

```{r args-match_expect, eval=FALSE}
match_expect(code_data = , expectation_pattern = '^expect_')
```

  -   `x` = _`code_data`_ : A `data.frame` representing parsed R code returned from `utils::getParseData()`, containing columns `token`,  `text`, `line1`, `line2`, `terminal`, and `text`.

  -   `token_text` = _`expectation_pattern`_ : The regular expression pattern that identifies the start of the expectation functions defaults to `'^expect_'`.

```{r match_expect, eval=FALSE, echo=FALSE}
match_expect <- function(code_data, expectation_pattern = '^expect_') {

  # function calls matching 'expectation_pattern'
  function_call_indices <- which(grepl("^SYMBOL_FUNCTION_CALL$", code_data[['token']]) &
                                 grepl(expectation_pattern, code_data[['text']]) &
                                 code_data[['terminal']])

  expectation_functions <- code_data[['text']][function_call_indices]

  # Return NULL if no '^expect_' functions are found
  if (length(expectation_functions) == 0) {
    return(NULL)
  }

  # Find line numbers 
  line_information <- lapply(function_call_indices, function(current_index) {
    indices_up_to_current <- tail(grep("expr", code_data[['token']][1:current_index]), 2)
    relevant_expr_index <- min(grep(sprintf("%s", code_data[['text']][current_index]),
                                    code_data[['text']][indices_up_to_current]))
    code_data[indices_up_to_current[relevant_expr_index], c("line1", "line2")]
  })
  
  combined_line_information <- do.call("rbind", line_information)

  expectation_info <- data.frame(
    expectation = expectation_functions,
    line1 = combined_line_information$line1,
    line2 = combined_line_information$line2,
    stringsAsFactors = FALSE
  )

  expectation_info

}
```

Below I'll compare `covrpage:::get_expect()` to `pickler::match_expect()`:

```{r compare-get_expect-match_expect, include=TRUE}
waldo::compare(
  x = covrpage:::get_expect(x = parsed_file_data, token_text = "^expect_"),
  y = match_expect(code_data = parsed_file_data, expectation_pattern = "^expect_")
)
```

`match_expect()` returns a `data.frame` containing the extracted `expect_()*` functions and their respective line numbers. This `data.frame` has columns `expectation`, `line1`, and `line2`. If no expectation functions are found, the function returns `NULL`.

### covrpage:::unrowname()

The `covrpage:::unrowname()` function modifies an input list of `data.frame`s by removing their rownames and appending a new column with a specific `label`. 

I've re-written `covrpage:::unrowname()` as `add_lbl_col()`.

```{r unrowname, eval=FALSE, echo=FALSE}
unrowname <- function(el, ret, label) {
  
  browser()
  
  x <- ret[[el]]

  nc <- ncol(x)

  x[[label]] <- el

  rownames(x) <- NULL

  x <- x[, c(c(nc + 1), 1:nc)]

  return(x)
}
```


#### pickler::add_lbl_col()

```{r args-add_lbl_col, eval=FALSE}
add_lbl_col(element_name = , expectations = , label_col_name = )
```

  -   `el` = _`element_name`_ : the element (typically a string) that will be used as the label for the new column.
  
  -   `ret` = _`expectations`_ : A list of data frames from which the specific `data.frame` is selected using the `element_name` parameter.
  
  -   `label` = _`label_col_name`_ : The name of the new column to be added to the `data.frame`, which will contain the value specified by `element_name`.
  
```{r add_lbl_col, eval=FALSE, echo=FALSE}
add_lbl_col <- function(element_name, expectations, label_col_name) {

  expectation_data <- expectations[[element_name]]

  num_columns <- ncol(expectation_data)

  expectation_data[[label_col_name]] <- element_name

  rownames(expectation_data) <- NULL

  reordered_expectation_data <- expectation_data[, c(num_columns + 1, 1:num_columns)]

  return(reordered_expectation_data)

}
```

This function is intended to be iterated on with a list of `data.frame`s from within `covrpage:::nest_expect()`, but we can compare it to `covrpage:::unrowname()` below: 

```{r compare-unrowname-add_lbl_col}
waldo::compare(
  covrpage:::unrowname(
    el = "parsed_logo", 
    ret = parsed_file_list, 
    label = "test"),
  add_lbl_col(
    element_name = "parsed_logo",
    parsed_data_list = parsed_file_list,
    col_name = "test"
  )
)
```


### covrpage:::nest_expect()

The `covrpage:::nest_expect()` function processes a list of parsed R code blocks, (tests), and extracts expectations from each block using the `covrpage:::get_expect()` function

```{r}
covrpage:::nest_expect(x = parsed_file_list)
```

  
```{r nest_expect, eval=FALSE, echo=FALSE}
nest_expect <- function(x) {
  ret <- lapply(x, get_expect)

  ret <- ret[!sapply(ret, is.null)]

  if (length(ret) == 0) {
    return(NULL)
  }

  ret <- lapply(names(ret), unrowname, ret = ret, label = "test")

  ret <- do.call("rbind", ret)

  ret
}
```



#### extract_expects()

**extract**: '*verb: physically remove, draw out*'

`covrpage:::nest_expect()` has been re-written as `extract_expects()` with the following arguments:

  -   `x` = _`test_code_list`_ : A list of parsed R code blocks. Each element of the list is expected to be a `data.frame` with a structure identical to what is returned by `utils::getParseData()`. These data frames represent parsed R code, corresponding to test blocks in the test files.
  
```{r extract_expects, eval=FALSE, echo=FALSE}
#' Combine Expectations from Parsed Test Blocks
#'
#' @param test_code_list A list of parsed test code blocks. Each element of the
#'  list is expected to be a `data.frame` with a structure identical to what is
#'  returned by `utils::getParseData()`. These data frames represent parsed R
#'  code, corresponding to test blocks in the test files.
#'
#' @return `extract_expects()` returns a `data.frame` that consolidates the
#' expectations extracted from each test file in the `tests/testthat/` folder.
#' The `data.frame` contains merged results from the individual tests, with 
#' additional columns for labeling and structuring the data. If no expectations
#'are found in any of the blocks, the function returns `NULL`.
#'
#' @export
#'
extract_expects <- function(test_code_list) {

  expectations_list <- lapply(test_code_list, match_expect)

  non_null_expectations_list <- expectations_list[!sapply(X = expectations_list, FUN = is.null)]

  # Return NULL if there are no non-null expectations
  if (length(non_null_expectations_list) == 0) {
    return(NULL)
  }

  # Remove row names and add a label column to each element in the list
  labeled_expectations_list <- lapply(X = names(non_null_expectations_list),
                                      FUN = function(test_name) {
                                        add_lbl_col(
                                          element_name = test_name,
                                          expectations = non_null_expectations_list,
                                          label_col_name = "test")
  })

  # Combine all labeled expectations into a single data frame
  combined_and_labeled_expectations <- do.call("rbind", labeled_expectations_list)

  combined_and_labeled_expectations
}
```

```{r compare-nest_expect-extract_expects}
waldo::compare(
  covrpage:::nest_expect(parsed_file_list),
  extract_expects(parsed_file_list)
)
```

```{r ast-nest_expect-alternatives, echo=FALSE}
ast(
  nest_expect("[x = list of parsed data.frames from getParseData(parse())]", 
              "applies get_expect() and unrowname() across multiple test files",
    get_expect("[x = parsed data.frame from getParseData(parse())]", 
               "[token_text = '^expect_']",  
               "returns data.frame"),
    unrowname("el = string element that will be used as the label for the new column." , 
              "ret = list of data.frames from which [el] is subsetted using ret[[el]]", 
              "label = new column name to be added to the data.frame (contains value specified by [el])")
  )
)
```


## Tests 

The tests functions (`describe()`, `it()`, and `test_that()`) are parsed with `nest_test()` and `map_test()`. Both sets of functions are wrapped in `map_testthat()`.

```{r ast-map_testthat, echo=FALSE, eval=TRUE, comment=''}
ast(
  map_testthat(
    map_test(
      nest_test(),
      nest_expect(
        get_expect(),
        unrowname()
      )
    )
  )
)
```


### covrpage:::nest_test()

```{r ast-map_testthat-map_test, eval=TRUE, echo=FALSE, comment=''}
ast(
  map_testthat(
    "[path] = ", 
    "adds 'file' column",
    map_test(
      "[path] = ", 
      "adds 'test' column",
      nest_test("[x] = list of parsed data.frames from getParseData(parse())", 
                "[token_text] = '^context$'")
      ),
      nest_expect("[x] = list of parsed data.frames from getParseData(parse())", 
                  "applies get_expect() and unrowname() across multiple test files",
        get_expect("[x] = parsed data.frame from getParseData(parse())", 
                   "[token_text] = '^expect_'",  
                   "returns data.frame"),
        unrowname("[el] = string element that will be used as the label for the new column" , 
                  "[ret] = list of data.frames from which [el] is subsetted using ret[[el]]", 
                  "[label] = column name added to the data.frame (contains value specified by [el])")
      )
    )
)
```


```{r}
str(
  covrpage:::nest_test(
    x = parsed_file_data, 
    token_text = "^context$")
)
```

#### pickler::match_tests()

`nest_test()` has been re-written as `match_tests()`

  -   `x` = _`test_data`_ : A `data.frame` representing a syntax tree of R code, typically obtained from `utils::getParseData()`

  -   `token_text` = _`context_pattern`_ : A regular expression as a string, used to match the text content of tokens in the syntax tree that signify the start of a test case. Defaults to `"^context$"` which is a placeholder for actual test function names like `test_that`.
  
```{r match_tests, eval=FALSE, echo=FALSE}
match_tests <- function(test_data, context_pattern = "^context$") {
  row_ids <- rownames(test_data)

  # Find indices of context function calls
  context_indices <- which(row_ids %in% test_data$parent[grepl("^SYMBOL_FUNCTION_CALL$", test_data$token) & grepl(context_pattern, test_data$text) & test_data$terminal])

  # Get indices of all rows that are children of the context
  child_indices <- which(row_ids %in% test_data$parent[context_indices])

  # Create a vector indicating the start of new context groups
  context_group_starts <- rep(0, nrow(test_data))
  context_group_starts[child_indices] <- 1

  # Cumulative sum to create group identifiers
  context_group_ids <- cumsum(context_group_starts)

  # Split the data by context groups
  grouped_test_data <- split(test_data, context_group_ids)

  # Assign names to each group based on their context
  names(grouped_test_data) <- sapply(grouped_test_data, function(single_test_data) {
      
      context_call_text <- single_test_data$text[grep("^SYMBOL_FUNCTION_CALL$", single_test_data$token)[1]]
      
      context_description <- eval(parse(text = single_test_data$text[grepl("^STR_CONST$", single_test_data$token)][1], keep.source = TRUE))
    
        if (context_call_text %in% c("test_that", "describe", "it")) {
          context_description <- sprintf("%s: %s", context_call_text, context_description)
        }
      
      context_description
    }, simplify = TRUE, USE.NAMES = TRUE)

  # Refine each group to include only relevant test data
  refined_grouped_test_data <- lapply(grouped_test_data, function(single_group_data) {
    relevant_index <- utils::tail(utils::head(which(single_group_data$parent == 0), 2), 1)
    if (length(relevant_index) == 0) {
      relevant_index <- 1
    }
    single_group_data[relevant_index:nrow(single_group_data), ]
  })

  refined_grouped_test_data
}
```


```{r}
waldo::compare(
  x = covrpage:::nest_test(x = parsed_file_data, token_text = "^context$"),
  y = match_tests(test_data = parsed_file_data, context_pattern = "^context$"))
```

### covrpage:::map_test()

`map_test()` adds the `context` and `description`, which includes a character string with the `text` from the parsed data above.

```{r}
covrpage:::map_test(path = system.file("dev", "tests", "testthat",
                                      "test-logo.R",
                                      package = "pickler")) |> str()
```

#### picker::parse_test_file()

`map_test()` has been re-written as `parse_test_file()`

```{r parse_test_file, eval=FALSE, echo=FALSE}
parse_test_file <- function(path) {

  parsed_tests <- utils::getParseData(x = parse(file = path, keep.source = TRUE), includeText = TRUE)

  if (is.null(parsed_tests)) {
    return(NULL)
  }

  ret <- lapply(
    match_tests(parsed_tests), FUN = function(xx) {
    ret_ <- lapply(
      match_tests(test_data = xx, context_pattern = "^test_that$|^describe$"),
      FUN = function(y) {
        SYMB <- y$text[grep(pattern = "^SYMBOL_FUNCTION_CALL$", x = y$token)[1]]
        switch(SYMB,
          describe = {
            extract_expects(
              test_code_list =
                match_tests(test_data = y, context_pattern = "^it$"))
          },
          test_that = {
            extract_expects(test_code_list = setNames(list(y), nm = " "))
          },
          {
            list()
          }
        )
      }
    )

    ret_ <- ret_[sapply(X = ret_, FUN = length) > 0]

    if (length(ret_) == 0) {
      return(NULL)
    }

    ret_ <- lapply(X = names(ret_),
                  FUN = add_lbl_col,
                  parsed_data_list = ret_,
                  col_name = "description"
      )

    ret_ <- do.call("rbind", ret_)

    ret_
  })

  ret <- ret[sapply(X = ret, FUN = length) > 0]

  if (length(ret) == 0) {
    return(NULL)
  }

  ret <- lapply(X = names(ret),
    FUN = add_lbl_col,
    parsed_data_list = ret,
    col_name = "context")

  ret <- do.call("rbind", ret)

  return(ret)
}
```

```{r , eval=TRUE}
waldo::compare(
  x = covrpage:::map_test(path = system.file("dev", "tests", "testthat",
                                      "test-logo.R",
                                      package = "pickler")), 
  y = parse_test_file(path = system.file("dev", "tests", "testthat",
                                      "test-logo.R",
                                      package = "pickler")))
```

### covrpage:::map_testthat()

`map_testthat()` iterates these functions and others over the test files in `tests/testthat/` (adding the `file` column).

```{r , eval=FALSE, echo=TRUE}
fs::dir_tree(path = system.file("dev", "tests", "testthat",
                                      package = "pickler"))
```

```bash
dev/tests/testthat/
  ├── _snaps
  ├── test-logo.R
  ├── test-pivot_string_long.R
  ├── test-rev_string.R
  └── test-split_cols.R
```


```{r}
str(
  covrpage:::map_testthat(path = system.file("dev", "tests", "testthat",
                                      package = "pickler"))
)

```

`map_testthat()` has been re-written as `parse_tests_dir()`

#### pickler::parse_tests_dir()

```{r parse_tests_dir, eval=FALSE, echo=FALSE}
parse_tests_dir <- function(path = "tests/testthat") {

  FILES <- list.files(path = path, full.names = TRUE, pattern = "^test(.*?)R$")

  ret <- stats::setNames(
    object = lapply(X = FILES, 
                    FUN = parse_test_file), 
    nm = basename(FILES))

  ret <- ret[sapply(ret, length) > 0]

  if (length(ret) == 0) {
    return(NULL)
  }

  ret <- lapply(
    X = names(ret), 
    FUN = add_lbl_col, 
    parsed_data_list = ret, 
    col_name = "file")

  ret <- do.call("rbind", ret)

  idx <- !(ret$test == " ")

  ret$description <- gsub(
    pattern = "describe: |test_that: ", 
    replacement = "", 
    x = ret$description)
  
  ret$test <- gsub(
    pattern = "it: ", 
    replacement = "", 
    x = ret$test)

  ret$test[!idx] <- ret$description[!idx]

  ret$test[idx] <- sprintf(
    fmt = "%s: %s", 
    ret$description[idx], 
    ret$test[idx])

  ret$description <- NULL

  ret
}
```

```{r}
str(
parse_tests_dir(path = system.file("dev", "tests", "testthat",
                                      package = "pickler"))
)
```


```{r}
waldo::compare(
  x = covrpage:::map_testthat(path = system.file("dev", "tests", "testthat",
                                      package = "pickler")), 
  y = parse_tests_dir(path = system.file("dev", "tests", "testthat",
                                      package = "pickler"))
)
```





```{r include=FALSE}
#' @title Nest Test Cases in R Code
#'
#' @description This function takes a syntax tree as input, typically generated 
#' by parsing R code, and organizes test cases based on the occurrence of 
#' specified tokens.  
#' 
#' @section Technical details:
#' `nest_test()` parses the provided syntax tree to extract and nest test cases
#' based on specified function calls. The function is part of a larger suite of
#' functions for processing and analyzing test cases. It is designed to work 
#' with test cases written using  common testing frameworks like `testthat`. 
#' The output is a list of nested  data frames, each representing a test case
#' block.
#' 
#' @param x A data frame representing a syntax tree of R code, typically 
#' obtained from `utils::getParseData()`.
#' @param token_text A regular expression as a string, used to match the 
#' text content of tokens in the syntax tree that signify the start of a 
#' test case. Defaults to `"^context$"` which is a placeholder for actual 
#' test function names like `test_that`.
#'
#' @return A list of data frames, each corresponding to a nested test case. 
#' The list is named using the first `SYMBOL_FUNCTION_CALL` token text in 
#' each nested case. Each data frame in the list contains a subset of the 
#' original syntax tree, corresponding to a specific test case.
#'
#' @export
#'
#' @section Related Functions:
#' This function is part of a suite including `nest_expect`, `get_expect`, 
#' `unrowname`, `map_test`, and `map_testthat`, which collectively process 
#' and analyze test cases in R code.
#'
#' @examples
#' # Assuming `x` is a syntax tree obtained from `utils::getParseData()`
#' nested_tests <- nest_test(x)
#' 
```



<!--

### BDD test examples

Below is an example feature description for `pickler::logo()`:

```Gherkin
Feature: Text-based Logo Generation
  As a user who calls the logo() function
  I want to generate an ASCII art text logo
  So that I can quickly insert the pickler logo
```

```{r}
logo()
```

We'll use a simple test for `logo()` stored in a `test-logo.R` file as an example. A Gherkin scenario for `logo()` have been written below:[^tests-inst]


``` Gherkin
  Scenario: User invokes the logo() function
    Given a user has installed the pickler package
    When a user calls the logo() function
    Then the pickler ASCII art is displayed in the console
    
  Scenario: User stores the output of logo()
    Given a user has access to the pickler package
    When the output from logo() is assigned to x
    Then the contents of x should be NULL
```

`test/testthat/` includes a single test file with the scenario above in the `desc` argument of a `test_that()` call, followed by `expect_null()`:

```{r test_that-pickler_logo, eval=TRUE}
test_that("Scenario: User stores the output of logo()
    Given a user has access to the pickler package
    When the output from logo() is assigned to x
    Then the contents of x should be NULL",
  code = {
        x <- logo()
        expect_null(x)
      })
```

[^tests-inst]: I've created a `tests/testthat/` folder in `inst/` so the tests can be accessed and won't interfere with the actual unit tests for `pickler`.


`pickler` scans the test files for calls to `describe()`, `test_that()`, or `it()` and captures the string content in the `description`/`desc` arguments.

## covrpage

`covrpage` creates a `tests/README.md` with three tables: 1) **Coverage summary**, 2) **Unit Test summary**, and 3) **Detailed Test Results**. I've included these tables in their original markdown format to demonstrate how the `tests/README.md` file is built. Below is a subset of the `tests/README.md` file in the `pickler` package.[^pickler-subset-funs]

[^pickler-subset-funs]: I've chosen to only include the tests for the example functions `pivot_string_long()`, `rev_string()`, and `split_cols()`.

###  Coverage summary

The **Coverage summary** is the output test coverage from the [covr](https://github.com/r-lib/covr) package.

``` verbatim
| Object                                                        | Coverage (%) |
|:--------------------------------------------------------------|:------------:|
| [R/pivot_string_long.R](../R/pivot_string_long.R)             |    100.00    |
| [R/rev_string.R](../R/rev_string.R)                           |    100.00    |
| [R/split_cols.R](../R/split_cols.R)                           |    100.00    |
```

The `Object` in the table above references the path to the file in the `R/` folder (i.e., `../R/<object_script.R>`).

### Unit Test summary

`covrpage` creates the following **Unit Test summary** table using the [testthat](https://github.com/r-lib/testthat) package.

``` verbatim
| file                                                          |
|:--------------------------------------------------------------|
| [test-pivot_string_long.R](testthat/test-pivot_string_long.R) |
| [test-rev_string.R](testthat/test-rev_string.R)               |
| [test-split_cols.R](testthat/test-split_cols.R)               |
```

The `file` links in the **Unit Test summary** table reference the test files in the `tests/testthat/` folder. This table also contains the number of tests in the file (`n`), the `time` the test took to run, and one of four test statuses (`error`, `failed`, `skipped`, `warning`).

``` verbatim
|   n  |  time | error | failed | skipped | warning |
|:----:|------:|------:|-------:|--------:|--------:|
|   13 | 0.107 |     0 |      0 |       0 |       0 |
|    6 | 0.061 |     0 |      0 |       0 |       0 |
|   17 | 0.323 |     0 |      0 |       0 |       0 |
```

### Detailed Test Results

The `Detailed Test Results` is contained in a `<details closed></details>` HTML tag. I've separated the `file` column table below:

<details closed>
<summary>Show `file` from **Detailed Test Results**</summary>

```verbatim
| file                                                              |
|:------------------------------------------------------------------|
| [test-pivot_string_long.R](testthat/test-pivot_string_long.R#L17) |
```

</details>

The `file` lists the link to the test file in `tests/testthat/`. Below, we can see the `context` shows the name of the function, and test shows the first line in the `describe()` function: 

```{r}
#| eval: false
describe("Feature: Pivot Single String into Long Format
  As a user,
  I want to pivot a single string into a long-format data.frame based on a separator
  So that I can analyze each unique item in the string separately",
  code = {
    # test code
  })
```


<details closed>
<summary>Show `context`, `test`, `status`, `n`, and `time` from **Detailed Test Results**</summary>

```verbatim
| context           | test                                          | status |   n | time |
|:------------------|:----------------------------------------------|:-------|----:|-----:|
| pivot_string_long | Feature: Pivot Single String into Long Format |        |     |      |
```

</details>

<details closed>
<summary>Show `context`, `test`, `status`, `n`, and `time` from **Detailed Test Results**</summary>

```verbatim
As a user, I want to pivot a single string into a long-format data.frame
based on a separator So that I can analyze each unique item in the
string separately.: Scenario 1: Pivot a single string using a default
separator Given a single string ‘a-b-c’ And a default separator:
\[^\[:alnum:\]\]+ When I call the pivot_string_long() function with this
string Then pivot_string_long() should return a data.frame with
‘unique_items’ and ‘string’ columns And the data.frame should contain
each unique item from the string And the ‘string’ column should contain
the original string for each unique item \|PASS \| 5\| 0.104\|
\|[test-pivot_string_long.R](testthat/test-pivot_string_long.R#L34)\|pivot_string_long
\|Feature: Pivot Single String into Long Format As a user, I want to
pivot a single string into a long-format data.frame based on a separator
So that I can analyze each unique item in the string separately.:
Scenario 2: Pivot multiple strings using a default separator Given a
vector of strings: c(‘a-b-c’, ‘d-e-f’) And a default separator
\[^\[:alnum:\]\]+ When I call the pivot_string_long() function with
these strings Then pivot_string_long() should return a combined
data.frame for all strings And each unique item from each string should
be in the ‘unique_items’ column And the corresponding original strings
should be in the ‘string’ column \|PASS \| 4\| 0.039\|
\|[test-pivot_string_long.R](testthat/test-pivot_string_long.R#L50)\|pivot_string_long
\|Feature: Pivot Single String into Long Format As a user, I want to
pivot a single string into a long-format data.frame based on a separator
So that I can analyze each unique item in the string separately.:
Scenario 3: Pivot a string using a custom separator Given a single
string ‘a1b2c’ And a custom separator ‘ When I call pivot_string_long()
with this string and separator Then the returned data.frame should
contain the unique items split by the custom separator And the ’string’
column should contain the original string for each unique item \|PASS \|
3\| 0.025\|
\|[test-pivot_string_long.R](testthat/test-pivot_string_long.R#L64_L65)\|pivot_string_long
\|Feature: Pivot Single String into Long Format As a user, I want to
pivot a single string into a long-format data.frame based on a separator
So that I can analyze each unique item in the string separately.:
Scenario 4: Provide an error message when an invalid separator is used
Given a single string ‘a-b-c’ And an invalid separator ’(\*)’ When I
call the pivot_string_long() function with this string and separator
Then the returned error should be ‘invalid regular expression’ \|PASS \|
1\| 0.028\|
\|[test-rev_string.R](testthat/test-rev_string.R#L12)\|rev_string
\|Scenario 1a: Reverse a simple string ‘hello’ Given a string ‘hello’
When I use the rev_string() function Then the output should be ‘olleh’
\|PASS \| 1\| 0.010\|
\|[test-rev_string.R](testthat/test-rev_string.R#L26)\|rev_string
\|Scenario 2a: Reverse another simple string ‘goodbye’ Given a string
‘goodbye’’ When I use the rev_string() function Then the output should
be ‘eybdoog’ \|PASS \| 1\| 0.011\|
\|[test-rev_string.R](testthat/test-rev_string.R#L41)\|rev_string
\|Feature: 1b Reverse a Mixed Case String As a user, I want to reverse
the characters in a string So that I can have the string displayed in
reverse order.: Scenario: Reverse a mixed case string ‘HeLlO’ Given a
string ‘HeLlO’ When I use the rev_string() function Then the output
should be ‘OlLeH’ \|PASS \| 1\| 0.011\|
\|[test-rev_string.R](testthat/test-rev_string.R#L55)\|rev_string
\|Feature: 2b: Reverse Another Mixed Case String As a user, I want to
reverse the characters in a string So that I can have the string
displayed in reverse order.: Scenario: Reverse another mixed case string
‘gOoDbYe’ Given a string ‘gOoDbYe’ When I use the rev_string() function
Then the output should be ‘eYbDoOg’ \|PASS \| 1\| 0.010\|
\|[test-rev_string.R](testthat/test-rev_string.R#L66)\|rev_string
\|Feature 3a: Reverse an Already Reversed String Scenario: Reverse an
already reversed string ‘OlLeH’ Given a string ‘OlLeH’ When I use the
rev_string() function Then the output should be ‘HeLlO’ \|PASS \| 1\|
0.010\|
\|[test-rev_string.R](testthat/test-rev_string.R#L76)\|rev_string
\|Feature 3b: Reverse a Complex String with Spaces Scenario: Reverse a
complex string with spaces ‘OlLeH eYbDoOg’ Given a string ‘OlLeH
eYbDoOg’ When I use the rev_string function Then the output should be
‘gOoDbYe HeLlO’ \|PASS \| 1\| 0.010\|
\|[test-split_cols.R](testthat/test-split_cols.R#L19)\|split_cols
\|Feature: Splitting Columns in data.frame As a data analyst, I want to
split a specified column into multiple columns based on a pattern So
that I can analyze the separated data more effectively.: Scenario A:
Split a column using the default pattern and prefix Given a data.frame
with a specific column And a default pattern ‘\[^\[:alnum:\]\]+’ And a
default column prefix ‘col’ When I call the split_cols() function on
this column Then the column should be split into multiple columns based
on the pattern And each new column should have the ‘col’ prefix followed
by a sequence number And the new columns should be appended to the
original data.frame \|PASS \| 5\| 0.043\|
\|[test-split_cols.R](testthat/test-split_cols.R#L38)\|split_cols
\|Feature: Splitting Columns in data.frame As a data analyst, I want to
split a specified column into multiple columns based on a pattern So
that I can analyze the separated data more effectively.: Scenario B:
Split a column in a data.frame using a custom pattern Given a data.frame
with a specific column And a custom pattern specified by the user When I
call the split_cols() function on this column with the custom pattern
Then the column should be split into multiple columns based on the
custom pattern And each new column should be prefixed with ‘col’
followed by a sequence number And the new columns should be appended to
the original data.frame \|PASS \| 5\| 0.043\|
\|[test-split_cols.R](testthat/test-split_cols.R#L56)\|split_cols
\|Feature: Splitting Columns in data.frame As a data analyst, I want to
split a specified column into multiple columns based on a pattern So
that I can analyze the separated data more effectively.: Scenario C:
Split a column in a data.frame using a custom column prefix Given a
data.frame with a specific column And a custom column prefix specified
by the user When I call the split_cols() function on this column with
the custom prefix Then the column should be split into multiple columns
based on the default pattern And each new column have the custom prefix
followed by a sequence number And the new columns should be appended to
the original data.frame \|PASS \| 5\| 0.036\|
\|[test-split_cols.R](testthat/test-split_cols.R#L69_L70)\|split_cols
\|Feature: Splitting Columns in data.frame As a data analyst, I want to
split a specified column into multiple columns based on a pattern So
that I can analyze the separated data more effectively.: Scenario D:
Provide an error message when the input data is not a data frame Given a
non-data frame input When I call the split_cols() function Then
split_cols() should returned an error \|PASS \| 1\| 0.022\|
\|[test-split_cols.R](testthat/test-split_cols.R#L79_L80)\|split_cols
\|Feature: Splitting Columns in data.frame As a data analyst, I want to
split a specified column into multiple columns based on a pattern So
that I can analyze the separated data more effectively.: Scenario E:
Provide an error message when the specified column is not in the
data.frame Given a data.frame without a specified column When I call the
split_cols() function with this column name Then split_cols() should
returned an error \|PASS \| 1\| 0.015\|
```

</details>

Here we can see the context references the context (the string argument passed to the )

The `README.md` documents the `file`, `context`, `test`, `status`, `n` and `time` to run.



```{r more-tests, include=FALSE, eval=FALSE}
describe("Feature: Pivot Single String into Long Format
  As a user,
  I want to pivot a single string into a long-format data.frame based on a separator
  So that I can analyze each unique item in the string separately.",
  code = {
    test_that("Scenario 1: Pivot a single string using a default separator
               Given a single string 'a-b-c'
               And a default separator '[^[:alnum:]]+'
               When I call the pivot_string_long() function with this string
               Then pivot_string_long() should return a data.frame with 'unique_items' and 'string' columns
               And the data.frame should contain each unique item from the string
               And the 'string' column should contain the original string for each unique item",
      code = {
          input_string <- "a-b-c"
          observed <- pivot_string_long(input_string)

          expect_true(is.data.frame(observed))
          expect_equal(names(observed), c("unique_items", "string"))
          expect_equal(nrow(observed), 3)
          expect_equal(observed$unique_items, c("a", "b", "c"))
          expect_equal(observed$string, c("a-b-c", NA, NA))
    })
    test_that("Scenario 2: Pivot multiple strings using a default separator
               Given a vector of strings ['a-b-c', 'd-e-f']
               And a default separator '[^[:alnum:]]+'
               When I call the pivot_string_long() function with these strings
               Then pivot_string_long() should return a combined data.frame for all strings
               And each unique item from each string should be in the 'unique_items' column
               And the corresponding original strings should be in the 'string' column",
      code = {
          input_strings <- c("a-b-c", "d-e-f")
          observed <- pivot_string_long(input_strings)

          expect_true(is.data.frame(observed))
          expect_equal(nrow(observed), 6)
          expect_equal(observed$unique_items, c("a", "b", "c", "d", "e", "f"))
          expect_equal(observed$string, c("a-b-c", NA, NA, "d-e-f", NA, NA))

    })
    test_that("Scenario 3: Pivot a string using a custom separator
               Given a single string 'a1b2c'
               And a custom separator '\\d'
               When I call pivot_string_long() with this string and separator
               Then the returned data.frame should contain the unique items split by the custom separator
               And the 'string' column should contain the original string for each unique item",
      code = {
          input_string <- "a1b2c"
          observed <- pivot_string_long(input_string, sep = "\\d")

          expect_true(is.data.frame(observed))
          expect_equal(observed$unique_items, c("a", "b", "c"))
          expect_equal(observed$string, c("a1b2c", NA, NA))

    })
    test_that("Scenario 4: Provide an error message when an invalid separator is used
               Given a single string 'a-b-c'
               And an invalid separator '(*)'
               When I call the pivot_string_long() function with this string and separator
               Then the returned error should be 'invalid regular expression'",
      code = {
        input_string <- "a-b-c"
        invalid_separator <- NA

        expect_error(pivot_string_long(input_string,
                     sep = invalid_separator))
    })

  })
test_that(desc = "include whitespace", code = {
  input <- c("one and two", "three")
  observed <- pivot_string_long(input, sep = ",?\\s*-?\\s*")
  output <- data.frame(unique_items =
      c("o", "n", "e", "",
        "a", "n", "d", "",
        "t", "w", "o",
        "t", "h", "r", "e", "e"),
    string = c("one and two",
      NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
      "three", NA, NA, NA, NA))
  expect_equal(object = observed, expected = output)
})
# Feature: Pivot String Long
#   As a user of pivot_string_long()
#   I want to specify a text column and a pattern
#   So that peform computations on the unique items.
#  Background: Input text data
#       Given a string or vector [string] with text columns
#       And a specified pattern [sep]
#  Scenario: Split a single string with default separator
#       Given a character [string] 'one-two-three'
#       When I pass the [string] to pivot_string_long()
#       Then [unique_items] column should contain rows: 'one, two, three'
#       And [string] column should contain the original 'one-two-three'
#       |unique_items |string        |
#       |-------------|--------------|
#       |one          |one-two-three |
#       |two          |NA            |
#       |three        |NA            |
# create input ----
input <- c("one-two-three")
# create observed output ----
observed <- pivot_string_long(input)
# compare against output ----
output <- data.frame(
  unique_items = c("one", "two", "three"),
  string = c("one-two-three", NA, NA)
)
```

-->
